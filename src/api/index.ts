import type { AxiosProgressEvent, GenericAbortSignal } from 'axios'
import { get, post } from '@/utils/request'
// import { httpStream } from '@/utils/request/httpStream'
import { useModelStore, useSettingStore } from '@/store'

export function fetchChatAPI<T = any>(
  prompt: string,
  options?: { conversationId?: string; parentMessageId?: string },
  signal?: GenericAbortSignal,
) {
  return post<T>({
    url: '/chat',
    data: { prompt, options },
    signal,
  })
}

export function fetchChatConfig<T = any>() {
  return post<T>({
    url: '/config',
  })
}

// export function fetchChatAPIProcessRaw(params: {
//   prompt: string
//   options?: { conversationId?: string; parentMessageId?: string }
//   signal?: AbortSignal
//   onMessage: (msg: string) => void
//   onFinish?: () => void
//   onError?: (err: any) => void
// }) {
//   const settingStore = useSettingStore()
//   const modelStore = useModelStore()

//   const data = {
//     prompt: params.prompt,
//     options: params.options,
//     systemMessage: settingStore.systemMessage,
//     temperature: settingStore.temperature,
//     top_p: settingStore.top_p,
//     provider: modelStore.selectedModel?.provider,
//   }

//   return httpStream({
//     url: '/llm/ask',
//     data,
//     signal: params.signal,
//     onMessage: params.onMessage,
//     onFinish: params.onFinish,
//     onError: params.onError,
//   })
// }

export function fetchChatAPIProcess<T = any>(params: {
  prompt: string
  options?: { conversationId?: string; parentMessageId?: string }
  signal?: GenericAbortSignal
  onDownloadProgress?: (progressEvent: AxiosProgressEvent) => void
}) {
  const settingStore = useSettingStore()
  const modelStore = useModelStore()

  const hash = window.location.hash // #/chat/1755670460056
  const parts = hash.split('/')
  // ä» URL å– conversationIdï¼Œå¦‚æœ params.options.conversationId å·²ç»ä¼ äº†ï¼Œå°±ä¼˜å…ˆç”¨ä¼ å…¥çš„
  const conversationId = parts.length > 2 ? parts[2] : null

  const data: Record<string, any> = {
    prompt: params.prompt,
    options: params.options,
    systemMessage: settingStore.systemMessage,
    temperature: settingStore.temperature,
    top_p: settingStore.top_p,
    provider: modelStore.selectedModel?.provider,
    conversationId,
  }

  return post<T>({
    url: '/llm/ask',
    data,
    signal: params.signal,
    onDownloadProgress: (e: AxiosProgressEvent) => {
      // ğŸ’¡ ä¿ç•™å“åº”æµç»™ç»„ä»¶å¤„ç†ï¼Œä¸åšè§£æï¼
      // console.log('111')
      // console.log(e)
      params.onDownloadProgress?.(e)
    },
  })
}

// export function fetchChatAPIProcess<T = any>(
//   params: {
//     prompt: string
//     options?: { conversationId?: string; parentMessageId?: string }
//     signal?: GenericAbortSignal
//     onDownloadProgress?: (progressEvent: AxiosProgressEvent) => void },
// ) {
//   const settingStore = useSettingStore()
//   const authStore = useAuthStore()
//   const modelStore = useModelStore()

//   let data: Record<string, any> = {
//     prompt: params.prompt,
//     options: params.options,
//   }

//   // if (authStore.isChatGPTAPI) {
//   //   data = {
//   //     ...data,
//   //     systemMessage: settingStore.systemMessage,
//   //     temperature: settingStore.temperature,
//   //     top_p: settingStore.top_p,
//   //   }
//   // }

//   if (authStore.is0GCompute) {
//     data = {
//       ...data,
//       systemMessage: settingStore.systemMessage,
//       temperature: settingStore.temperature,
//       top_p: settingStore.top_p,
//       provider: modelStore.selectedModel?.provider,  // è¿½åŠ providerå­—æ®µ
//     }
//   }

//   return post<T>({
//     url: '/llm/ask',
//     data,
//     signal: params.signal,
//     onDownloadProgress: (e) => {
//       const xhr = e.event?.target
//       const { responseText } = xhr
//       //console.log('ğŸ’¡ åŸå§‹ responseText', responseText)

//       const lastIndex = responseText.lastIndexOf('\n', responseText.length - 2)
//       let chunk = responseText
//       //console.log('ğŸ“Œ è§£æ chunk', chunk)
//       if (lastIndex !== -1)
//         chunk = responseText.substring(lastIndex)

//       try {
//         const res = JSON.parse(chunk)
//         //console.log('âœ… è§£æåæ•°æ®', res)

//         // âœ… è½¬æ¢åç«¯è¿”å›ä¸ºå‰ç«¯é¢„æœŸæ ¼å¼
//         const transformed = {
//           text: res?.data?.choices?.[0]?.message?.content ?? '',
//           conversationId: null, // ä½ å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè¡¥å……
//           id: res?.data?.id ?? Date.now().toString(), // ä¿ç•™åŸ ID æˆ–ç”Ÿæˆæ–° ID
//           detail: {
//             choices: [
//               {
//                 finish_reason: res?.data?.choices?.[0]?.finish_reason ?? 'stop',
//               },
//             ],
//           },
//         }

//         // è°ƒç”¨å‰ç«¯åŸå§‹çš„å›è°ƒï¼Œä¼ªé€  responseText
//         params.onDownloadProgress?.({
//           ...e,
//           event: {
//             ...e.event,
//             target: {
//               responseText: JSON.stringify(transformed),
//             },
//           },
//         })
//       } catch (err) {
//         console.warn('å“åº”æ ¼å¼è§£æå¤±è´¥', err)
//       }
//     },
//   })

// }

export function fetchSession<T>() {
  return post<T>({
    url: '/session',
  })
}

export function fetchModelsOptions<T>() {
  return get<T>({
    url: '/llm/models',
  })
}

export function fetchVerify<T>(token: string) {
  return post<T>({
    url: '/verify',
    data: { token },
  })
}
